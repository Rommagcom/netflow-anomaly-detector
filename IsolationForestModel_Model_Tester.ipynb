{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model using  NetFlow files from csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependecies\n",
    "pip install numpy,pandas,xgboost,sklearn,pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier,IsolationForest\n",
    "from sklearn.cluster import DBSCAN,KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from pickle import dump\n",
    "import time\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set can be downloaded from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://rdm.uq.edu.au/files/650f1fa0-ef9c-11ed-b5f6-b1a04f482c13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns needed from csv files\n",
    "Example:\n",
    "172.31.66.17,51128,23.36.69.189,443,6,91.0,152,0,3,0,194,4285680,0,anomaly_name\n",
    "\n",
    "After data normalization some field will be dropped\n",
    "'src_ip', 'dst_ip','l7_proto','anomaly'\n",
    "In this way these values can be written randomly and will be not used in learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "field 'label' if equels 0 - is normal, if equals 1 - is anomaly, training model dont take it in to cosideration, just needed for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_fields = [\n",
    "    \"src_ip\",\n",
    "    \"src_port\",\n",
    "    \"dst_ip\",\n",
    "    \"dst_port\",\n",
    "    \"ip_protocol\",\n",
    "    \"l7_proto\",\n",
    "    \"in_bytes\",\n",
    "    \"out_bytes\",\n",
    "    \"in_pkts\",\n",
    "    \"out_pkts\",\n",
    "    \"tcp_flags\",\n",
    "    \"duration\",\n",
    "    \"label\",\n",
    "    \"anomaly\",\n",
    "    \"notneeded\"\n",
    "]\n",
    "\n",
    "with open(\"datasets/NF-UQ-NIDS.csv\", \"r\") as csvfile:\n",
    "    # pass input data stream as open(\"data.csv\", \"r\") to csv.reader for testing\n",
    "    # read and process line by line don't read into list\n",
    "    df_new = pd.read_csv(csvfile, names=flow_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worms_mask = df_new['anomaly'] != 'Benign'\n",
    "df_worm = df_new.loc[df_worms_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaler for data standartization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_scl(df_num, cols):\n",
    "    print(\"Original values:\\n\", df_num)\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    scaler_temp = scaler.fit_transform(df_num)\n",
    "\n",
    "    std_df = pd.DataFrame(scaler_temp, columns =cols)\n",
    "\n",
    "    #print(\"\\nScaled values:\\n\", std_df)\n",
    "\n",
    "    return std_df\n",
    "\n",
    "cat_cols = ['ip_protocol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process standatrization and normalization primitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dataframe):\n",
    "    df_num = dataframe.drop(cat_cols, axis=1)\n",
    "    num_cols = df_num.columns\n",
    "    scaled_df = do_scl(df_num, num_cols)\n",
    "\n",
    "    dataframe.drop(labels=num_cols, axis=\"columns\", inplace=True)\n",
    "    dataframe[num_cols] = scaled_df[num_cols]\n",
    "\n",
    "    #print(\"Before encoding:\")\n",
    "    #print(dataframe['ip_protocol'])\n",
    "    \n",
    "    #uncomment for categorical features\n",
    "    #dataframe = pd.get_dummies(dataframe, columns = ['ip_protocol'])\n",
    "\n",
    "    #print(\"\\nColumns after encoding:\")\n",
    "    #print(dataframe.filter(regex='^protocol_type_'))\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop not necessary columns and process scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test =df_worm.drop(['src_ip', 'dst_ip','l7_proto','anomaly','notneeded'] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.reset_index(inplace=True)\n",
    "df_test.drop(['index'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale fetures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original values:\n",
      "          src_port  dst_port  in_bytes  out_bytes  in_pkts  out_pkts  \\\n",
      "0           43025        25     41290       2080       48        24   \n",
      "1           64923        80       994        256       10         6   \n",
      "2            9022       111       552        336       10         8   \n",
      "3            1752        25      3022       1636       20        20   \n",
      "4           53967       111       168          0        2         0   \n",
      "...           ...       ...       ...        ...      ...       ...   \n",
      "2786840     46307        22      4854       5812       32        36   \n",
      "2786841     50032      4433   2334879     897197      553       303   \n",
      "2786842      4444     49160    171528  209050328     3009      3958   \n",
      "2786843      4433     50032    303896  151306895     4974     13807   \n",
      "2786844     49160      4444  40102320      37280      763       590   \n",
      "\n",
      "         tcp_flags  duration  label  \n",
      "0               27       803      1  \n",
      "1               19       189      1  \n",
      "2               19       678      1  \n",
      "3               19       789      1  \n",
      "4                0         0      1  \n",
      "...            ...       ...    ...  \n",
      "2786840         26   4266525      1  \n",
      "2786841         26   4273697      1  \n",
      "2786842         24   4175036      1  \n",
      "2786843         24   4213229      1  \n",
      "2786844         24   4270068      1  \n",
      "\n",
      "[2786845 rows x 9 columns]\n",
      "\n",
      "Scaled values:\n",
      "          src_port    dst_port      in_bytes      out_bytes  in_pkts  out_pkts  \\\n",
      "0       -0.452239   -0.151515     82.477912       2.771739    11.00       4.6   \n",
      "1        0.987378    0.000000      1.562249       0.293478     1.50       1.0   \n",
      "2       -2.687660    0.085399      0.674699       0.402174     1.50       1.4   \n",
      "3       -3.165604   -0.151515      5.634538       2.168478     4.00       3.8   \n",
      "4        0.267109    0.085399     -0.096386      -0.054348    -0.50      -0.2   \n",
      "...           ...         ...           ...            ...      ...       ...   \n",
      "2786840 -0.236474   -0.159780      9.313253       7.842391     7.00       7.0   \n",
      "2786841  0.008415   11.991736   4688.078313    1218.963315   137.25      60.4   \n",
      "2786842 -2.988627  135.206612    344.000000  284035.717391   751.25     791.4   \n",
      "2786843 -2.989350  137.608815    609.799197  205579.966033  1242.50    2761.2   \n",
      "2786844 -0.048912   12.022039  80526.313253      50.597826   189.75     117.8   \n",
      "\n",
      "         tcp_flags     duration  label  \n",
      "0         0.333333     0.466152    0.0  \n",
      "1        -0.555556     0.101544    0.0  \n",
      "2        -0.555556     0.391924    0.0  \n",
      "3        -0.555556     0.457838    0.0  \n",
      "4        -2.666667    -0.010689    0.0  \n",
      "...            ...          ...    ...  \n",
      "2786840   0.222222  2533.555226    0.0  \n",
      "2786841   0.222222  2537.814133    0.0  \n",
      "2786842   0.000000  2479.226841    0.0  \n",
      "2786843   0.000000  2501.906770    0.0  \n",
      "2786844   0.000000  2535.659145    0.0  \n",
      "\n",
      "[2786845 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "scaled_test = process(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in to training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_live = scaled_test['label'].values\n",
    "y_test_live = y_test_live.astype('int')\n",
    "\n",
    "X_test_live = scaled_test.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators=1500 - the higher the value, the longer the training takes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start learning process\n",
    "These values can be tuned for best performance:\n",
    "'random_state=47, contamination=0.01,n_estimators=1000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start prediction. Trained model know only x_train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "from pickle import load\n",
    "with open(\"IsolationForestModel_100.pkl\", \"rb\") as f:\n",
    "    clf = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_live = clf.predict(X_test_live)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize predicted values to source values for testing prediction:  0- is normal behviour, 1 - is anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_live[predict_test_live == 1] = 0\n",
    "predict_test_live[predict_test_live == -1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate predicted values to known values and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_live = metrics.accuracy_score(y_test_live,predict_test_live)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Accuracy IsolationForestClassifier 99.99425874061887  Predict Accuracy \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999425874061887"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Predict Accuracy \" + \"IsolationForestClassifier\" + \" {}  Predict Accuracy \".format(test_accuracy_live*100))\n",
    "test_accuracy_live"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
